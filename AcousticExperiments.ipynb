{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acoustic Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.constants as const\n",
    "\n",
    "from scipy.io import wavfile\n",
    "from sklearn import preprocessing\n",
    "from scipy import signal\n",
    "\n",
    "from scipy.signal import butter, firwin, lfilter\n",
    "from scipy.signal import freqz\n",
    "from scipy.signal import argrelmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants & Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data_directory = \"data\"\n",
    "output_data_directory = \"out\"\n",
    "\n",
    "sample_rate = 44100\n",
    "tone_duration = 0.05\n",
    "tone_frequency0 = 2000\n",
    "tone_frequency1 = 6000\n",
    "filter_order = 200\n",
    "\n",
    "def normalize_data(data):\n",
    "    return data/0x7FFF\n",
    "\n",
    "def filter_data(data, low_cut_frequency, high_cut_frequency, order, sample_rate=44100):\n",
    "    b = firwin(order+1, [low_cut_frequency, high_cut_frequency], pass_zero=False, nyq=sample_rate/2)\n",
    "    a = [1.0]\n",
    "    # return data\n",
    "    return lfilter(b, a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tone Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sinwave_tone(frequency, duration, sample_rate):\n",
    "    return np.sin(2 * math.pi * np.arange(math.ceil(sample_rate * duration)) * frequency / sample_rate) * 0x7FFF\n",
    "\n",
    "def chirp_tone(frequency0, frequency1, duration, phase0=0, sample_rate=44100):\n",
    "    num_samples = math.ceil(sample_rate * duration);\n",
    "    k = (frequency1 - frequency0)/num_samples\n",
    "    return np.sin(phase0+2*math.pi*(np.arange(num_samples)*frequency0/sample_rate+k/2*np.arange(num_samples)**2/sample_rate)) * 0x7FFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tone(tone_frequency0, tone_frequency1, tone_duration, sample_rate, filter_order):\n",
    "    tone_data = chirp_tone(tone_frequency0, tone_frequency1, tone_duration, sample_rate)\n",
    "    # wavfile.write(input_data_directory+\"/audio/tone.wav\", sample_rate, tone_data.astype(np.int16))\n",
    "    tone_data = filter_data(normalize_data(tone_data), tone_frequency0, tone_frequency1, filter_order)\n",
    "    return tone_data\n",
    "\n",
    "def load_sample(path, tone_frequency0, tone_frequency1, filter_order):\n",
    "    sample_rate, sample_data = wavfile.read(path)\n",
    "    return sample_rate, filter_data(normalize_data(sample_data), tone_frequency0, tone_frequency1, filter_order)\n",
    "       \n",
    "def tone_correlation(sample_data, tone_frequency0, tone_frequency1, tone_data):\n",
    "    correlation = sp.correlate(sample_data, tone_data, 'valid')\n",
    "    return correlation\n",
    "\n",
    "def tone_recognition(sample_data, sample_rate, duration):\n",
    "    last_index = 0\n",
    "    tones = []\n",
    "    tone_candidates = argrelmax(sample_data, order=math.ceil(duration*sample_rate))[0]\n",
    "    for candidate in tone_candidates:\n",
    "        tones.append((candidate, sample_data[candidate]))\n",
    "    tones.sort(key=lambda tup: tup[1])\n",
    "    tones.reverse()\n",
    "    \n",
    "    return tones\n",
    "\n",
    "def compute_etoa(tones, sample_rate):\n",
    "    if len(tones) < 2:\n",
    "        raise NameError(\"Insufficient Tones Detected\")\n",
    "    else:\n",
    "        return abs(tones[0][0]-tones[1][0])/sample_rate\n",
    "    \n",
    "def compute_distance(etoa_a, etoa_b, d_aa, d_bb, c=340.29):\n",
    "    return (c/2) * (etoa_a - etoa_b) + (d_aa + d_bb)\n",
    "\n",
    "def device_distance(device_a_path, device_b_path, tone_frequency0, tone_frequency1, tone_duration, sample_rate, filter_order, verbose=False):\n",
    "    tone_data = generate_tone(tone_frequency0, tone_frequency1, tone_duration, sample_rate, filter_order)\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.plot(tone_data)\n",
    "        \n",
    "    if verbose:\n",
    "        print(\"Device A Sample:\", device_a_path)\n",
    "        print(\"Device B Sample:\", device_b_path)\n",
    "    \n",
    "    \n",
    "    device_a_sample_rate, device_a_sample_data = load_sample(device_a_path, tone_frequency0, tone_frequency1, filter_order)\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.suptitle(\"Device A Waveform\", fontsize=16)\n",
    "        plt.plot(device_a_sample_data)\n",
    "    \n",
    "    device_b_sample_rate, device_b_sample_data = load_sample(device_b_path, tone_frequency0, tone_frequency1, filter_order)\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.suptitle(\"Device B Waveform\", fontsize=16)\n",
    "        plt.plot(device_b_sample_data)\n",
    "    \n",
    "    \n",
    "    device_a_correlation = tone_correlation(device_a_sample_data,\n",
    "                                           tone_frequency0,\n",
    "                                           tone_frequency1,\n",
    "                                           tone_data)\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.suptitle(\"Device A Correlation\", fontsize=16)\n",
    "        plt.plot(device_a_correlation)\n",
    "    \n",
    "    device_b_correlation = tone_correlation(device_b_sample_data,\n",
    "                                           tone_frequency0,\n",
    "                                           tone_frequency1,\n",
    "                                           tone_data)\n",
    "    if verbose:\n",
    "        plt.figure()\n",
    "        plt.suptitle(\"Device B Correlation\", fontsize=16)\n",
    "        plt.plot(device_b_correlation)\n",
    "    \n",
    "    \n",
    "    device_a_tones = tone_recognition(device_a_correlation, sample_rate, tone_duration)\n",
    "    if verbose:\n",
    "        print(\"Device A\")\n",
    "        print(\"A total of\",len(device_a_tones),\"tones were detected.\")\n",
    "        print(\"The best candidates are (\",device_a_tones[0][0],\",\",device_a_tones[0][1],\") and (\",device_a_tones[1][0],\",\",device_a_tones[1][1],\")\")  \n",
    "        print(\"A total of\",len(device_a_tones),\"tones were detected.\")    \n",
    "    \n",
    "    device_b_tones = tone_recognition(device_b_correlation, sample_rate, tone_duration)\n",
    "    if verbose: \n",
    "        print(\"Device B\")\n",
    "        print(\"The best candidates are (\",device_b_tones[0][0],\",\",device_b_tones[0][1],\") and (\",device_b_tones[1][0],\",\",device_b_tones[1][1],\")\")  \n",
    "        print(\"A total of\",len(device_b_tones),\"tones were detected.\")\n",
    "    \n",
    "    \n",
    "    device_a_etoa = compute_etoa(device_a_tones, sample_rate)\n",
    "    if verbose: \n",
    "        print(\"Device A ETOA:\",device_a_etoa)\n",
    "        \n",
    "    device_b_etoa = compute_etoa(device_b_tones, sample_rate)\n",
    "    if verbose:\n",
    "        print(\"Device B ETOA:\",device_b_etoa)\n",
    "\n",
    "    \n",
    "    distance = compute_distance(device_a_etoa, device_b_etoa, 0.04, 0.04)\n",
    "    if verbose:\n",
    "        print(\"Distance between devices in meters:\", distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial Files:\" data/audio/trial-0-chirp-0.5m-da.wav \"and\" data/audio/trial-0-chirp-0.5m-db.wav \"\n",
      "Distance between devices in meters: 0.519830612245\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "trials = [\n",
    "    (input_data_directory+\"/audio/trial-0-chirp-0.5m-da.wav\", input_data_directory+\"/audio/trial-0-chirp-0.5m-db.wav\"),\n",
    "    #(input_data_directory+\"/audio/trial-1-chirp-0.5m-da.wav\", input_data_directory+\"/audio/trial-1-chirp-0.5m-db.wav\"),\n",
    "    #(input_data_directory+\"/audio/trial-2-chirp-0.5m-da.wav\", input_data_directory+\"/audio/trial-2-chirp-0.5m-db.wav\"),\n",
    "    #(input_data_directory+\"/audio/trial-0-chirp-1m-da.wav\", input_data_directory+\"/audio/trial-0-chirp-1m-db.wav\"),\n",
    "    #(input_data_directory+\"/audio/trial-1-chirp-1m-da.wav\", input_data_directory+\"/audio/trial-1-chirp-1m-db.wav\"),\n",
    "    #(input_data_directory+\"/audio/trial-2-chirp-1m-da.wav\", input_data_directory+\"/audio/trial-2-chirp-1m-db.wav\")\n",
    "]\n",
    "\n",
    "for trial in trials:\n",
    "    print(\"Trial Files:\\\"\",trial[0],\"\\\"and\\\"\",trial[1],\"\\\"\")\n",
    "    print(\"Distance between devices in meters:\", device_distance(trial[0], trial[1],\n",
    "                                                                 tone_frequency0,\n",
    "                                                                 tone_frequency1,\n",
    "                                                                 tone_duration,\n",
    "                                                                 sample_rate,\n",
    "                                                                 filter_order,\n",
    "                                                                 verbose=False))\n",
    "    print(\"--------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
